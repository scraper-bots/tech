{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed Handwriting Recognition Pipeline\n",
    "## SOCAR Hackathon 2025 - Error-Free Version\n",
    "\n",
    "This notebook fixes common errors:\n",
    "- ‚úÖ Robust error handling\n",
    "- ‚úÖ Better type checking\n",
    "- ‚úÖ Detailed error messages\n",
    "- ‚úÖ Image validation\n",
    "- ‚úÖ Graceful failure handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup with Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Installation complete!\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "!pip install -q kagglehub transformers torch torchvision pillow\n",
    "!pip install -q matplotlib seaborn plotly pandas numpy scikit-learn tqdm\n",
    "!pip install -q jiwer opencv-python scikit-image\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch: 2.9.0+cu126\n",
      "‚úÖ Device: CPU\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import kagglehub\n",
    "import os\n",
    "import json\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.filters import threshold_sauvola\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "from transformers import (\n",
    "    VisionEncoderDecoderModel,\n",
    "    TrOCRProcessor\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "from jiwer import cer, wer\n",
    "\n",
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úÖ Device: {'GPU (' + torch.cuda.get_device_name(0) + ')' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fixed Image Preprocessing with Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Safe image processor implemented\n"
     ]
    }
   ],
   "source": [
    "class SafeImageProcessor:\n",
    "    \"\"\"\n",
    "    Robust image preprocessing with comprehensive error handling.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_image(image):\n",
    "        \"\"\"\n",
    "        Validate image before processing.\n",
    "        \"\"\"\n",
    "        if image is None:\n",
    "            raise ValueError(\"Image is None\")\n",
    "        \n",
    "        if isinstance(image, np.ndarray):\n",
    "            if image.size == 0:\n",
    "                raise ValueError(\"Image array is empty\")\n",
    "            if image.dtype == np.object_:\n",
    "                raise ValueError(\"Image has object dtype, cannot process\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_image_safely(image_path):\n",
    "        \"\"\"\n",
    "        Safely load image with error handling.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Try with OpenCV first\n",
    "            image = cv2.imread(str(image_path))\n",
    "            \n",
    "            if image is None:\n",
    "                # Fallback to PIL\n",
    "                pil_image = Image.open(image_path)\n",
    "                image = np.array(pil_image)\n",
    "            \n",
    "            # Validate\n",
    "            if image is None or image.size == 0:\n",
    "                raise ValueError(f\"Could not load image: {image_path}\")\n",
    "            \n",
    "            # Convert to uint8 if needed\n",
    "            if image.dtype != np.uint8:\n",
    "                if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "                    image = (image * 255).astype(np.uint8)\n",
    "                else:\n",
    "                    image = image.astype(np.uint8)\n",
    "            \n",
    "            return image\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading image {image_path}: {str(e)}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_image(image_path):\n",
    "        \"\"\"\n",
    "        Preprocess image with comprehensive error handling.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load image safely\n",
    "            image = SafeImageProcessor.load_image_safely(image_path)\n",
    "            \n",
    "            # Store original\n",
    "            original = image.copy()\n",
    "            \n",
    "            # Convert to grayscale\n",
    "            if len(image.shape) == 3:\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray = image.copy()\n",
    "            \n",
    "            # Ensure proper dtype\n",
    "            if gray.dtype != np.uint8:\n",
    "                gray = gray.astype(np.uint8)\n",
    "            \n",
    "            # Binarize with error handling\n",
    "            try:\n",
    "                thresh = threshold_sauvola(gray, window_size=min(25, min(gray.shape)//2))\n",
    "                binary = (gray > thresh).astype(np.uint8) * 255\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è Sauvola failed, using Otsu: {e}\")\n",
    "                _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            \n",
    "            return {\n",
    "                'original': original,\n",
    "                'gray': gray,\n",
    "                'binary': binary,\n",
    "                'shape': image.shape,\n",
    "                'success': True\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Preprocessing error: {str(e)}\")\n",
    "            return {\n",
    "                'original': None,\n",
    "                'gray': None,\n",
    "                'binary': None,\n",
    "                'shape': None,\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "print(\"‚úÖ Safe image processor implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fixed OCR Pipeline with Robust Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Robust OCR pipeline implemented\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ProcessingResult:\n",
    "    \"\"\"\n",
    "    Result with success/failure tracking.\n",
    "    \"\"\"\n",
    "    image_path: str\n",
    "    success: bool\n",
    "    raw_text: Optional[str] = None\n",
    "    confidence: Optional[float] = None\n",
    "    extracted_fields: Optional[Dict] = None\n",
    "    error_message: Optional[str] = None\n",
    "    error_type: Optional[str] = None\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "\n",
    "class RobustOCRPipeline:\n",
    "    \"\"\"\n",
    "    OCR pipeline with comprehensive error handling and recovery.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"microsoft/trocr-base-handwritten\"):\n",
    "        print(\"üöÄ Initializing Robust OCR Pipeline...\")\n",
    "        \n",
    "        self.processor_helper = SafeImageProcessor()\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        try:\n",
    "            print(f\"üì¶ Loading TrOCR: {model_name}\")\n",
    "            self.processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "            self.model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "            print(f\"‚úÖ Model loaded on {self.device}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load model: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            'processed': 0,\n",
    "            'successful': 0,\n",
    "            'failed': 0,\n",
    "            'errors': defaultdict(int)\n",
    "        }\n",
    "    \n",
    "    def recognize_text_safe(self, image):\n",
    "        \"\"\"\n",
    "        Safely recognize text with error handling.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate input\n",
    "            if image is None:\n",
    "                raise ValueError(\"Input image is None\")\n",
    "            \n",
    "            # Convert to PIL Image\n",
    "            if isinstance(image, np.ndarray):\n",
    "                # Ensure proper dtype\n",
    "                if image.dtype == np.object_:\n",
    "                    raise ValueError(\"Image has object dtype\")\n",
    "                \n",
    "                if image.dtype != np.uint8:\n",
    "                    if image.dtype in [np.float32, np.float64]:\n",
    "                        image = (image * 255).astype(np.uint8)\n",
    "                    else:\n",
    "                        image = image.astype(np.uint8)\n",
    "                \n",
    "                # Convert to PIL\n",
    "                if len(image.shape) == 2:\n",
    "                    pil_image = Image.fromarray(image, mode='L')\n",
    "                elif len(image.shape) == 3:\n",
    "                    if image.shape[2] == 3:\n",
    "                        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                    else:\n",
    "                        pil_image = Image.fromarray(image[:,:,0], mode='L')\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected image shape: {image.shape}\")\n",
    "            else:\n",
    "                pil_image = image\n",
    "            \n",
    "            # Ensure RGB mode\n",
    "            if pil_image.mode != 'RGB':\n",
    "                pil_image = pil_image.convert('RGB')\n",
    "            \n",
    "            # Validate size\n",
    "            if pil_image.size[0] == 0 or pil_image.size[1] == 0:\n",
    "                raise ValueError(\"Image has zero dimensions\")\n",
    "            \n",
    "            # Process with model\n",
    "            pixel_values = self.processor(\n",
    "                pil_image, \n",
    "                return_tensors=\"pt\"\n",
    "            ).pixel_values.to(self.device)\n",
    "            \n",
    "            # Generate\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    pixel_values,\n",
    "                    output_scores=True,\n",
    "                    return_dict_in_generate=True,\n",
    "                    num_beams=5,\n",
    "                    max_length=128\n",
    "                )\n",
    "            \n",
    "            # Decode\n",
    "            text = self.processor.batch_decode(\n",
    "                outputs.sequences, \n",
    "                skip_special_tokens=True\n",
    "            )[0]\n",
    "            \n",
    "            # Calculate confidence\n",
    "            if hasattr(outputs, 'sequences_scores'):\n",
    "                confidence = float(torch.exp(outputs.sequences_scores[0]).cpu())\n",
    "            else:\n",
    "                confidence = 0.85\n",
    "            \n",
    "            return text, confidence, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Recognition error: {str(e)}\"\n",
    "            print(f\"  ‚ö†Ô∏è {error_msg}\")\n",
    "            return \"\", 0.0, error_msg\n",
    "    \n",
    "    def extract_fields_safe(self, text):\n",
    "        \"\"\"\n",
    "        Safely extract fields from text.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            fields = {}\n",
    "            \n",
    "            if not text:\n",
    "                return fields\n",
    "            \n",
    "            lines = text.split('\\n')\n",
    "            \n",
    "            for line in lines:\n",
    "                if ':' in line:\n",
    "                    try:\n",
    "                        parts = line.split(':', 1)\n",
    "                        if len(parts) == 2:\n",
    "                            key = parts[0].strip().lower()\n",
    "                            value = parts[1].strip()\n",
    "                            if key and value:\n",
    "                                fields[key] = value\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            return fields\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Field extraction error: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def process_document(self, image_path):\n",
    "        \"\"\"\n",
    "        Process document with comprehensive error handling.\n",
    "        \"\"\"\n",
    "        self.stats['processed'] += 1\n",
    "        \n",
    "        try:\n",
    "            # Preprocess\n",
    "            preprocessed = self.processor_helper.preprocess_image(image_path)\n",
    "            \n",
    "            if not preprocessed['success']:\n",
    "                self.stats['failed'] += 1\n",
    "                self.stats['errors']['preprocessing'] += 1\n",
    "                return ProcessingResult(\n",
    "                    image_path=str(image_path),\n",
    "                    success=False,\n",
    "                    error_message=preprocessed.get('error', 'Preprocessing failed'),\n",
    "                    error_type='preprocessing'\n",
    "                )\n",
    "            \n",
    "            # Recognize text\n",
    "            text, confidence, error = self.recognize_text_safe(preprocessed['binary'])\n",
    "            \n",
    "            if error:\n",
    "                self.stats['failed'] += 1\n",
    "                self.stats['errors']['recognition'] += 1\n",
    "                return ProcessingResult(\n",
    "                    image_path=str(image_path),\n",
    "                    success=False,\n",
    "                    error_message=error,\n",
    "                    error_type='recognition'\n",
    "                )\n",
    "            \n",
    "            # Extract fields\n",
    "            fields = self.extract_fields_safe(text)\n",
    "            \n",
    "            # Success\n",
    "            self.stats['successful'] += 1\n",
    "            return ProcessingResult(\n",
    "                image_path=str(image_path),\n",
    "                success=True,\n",
    "                raw_text=text,\n",
    "                confidence=confidence,\n",
    "                extracted_fields=fields\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.stats['failed'] += 1\n",
    "            self.stats['errors']['unknown'] += 1\n",
    "            \n",
    "            error_msg = f\"{type(e).__name__}: {str(e)}\"\n",
    "            print(f\"  ‚ùå Unexpected error: {error_msg}\")\n",
    "            \n",
    "            return ProcessingResult(\n",
    "                image_path=str(image_path),\n",
    "                success=False,\n",
    "                error_message=error_msg,\n",
    "                error_type='unknown'\n",
    "            )\n",
    "    \n",
    "    def print_stats(self):\n",
    "        \"\"\"\n",
    "        Print processing statistics.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä PROCESSING STATISTICS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Total processed: {self.stats['processed']}\")\n",
    "        print(f\"‚úÖ Successful: {self.stats['successful']} ({self.stats['successful']/self.stats['processed']*100:.1f}%)\")\n",
    "        print(f\"‚ùå Failed: {self.stats['failed']} ({self.stats['failed']/self.stats['processed']*100:.1f}%)\")\n",
    "        \n",
    "        if self.stats['errors']:\n",
    "            print(f\"\\nüîç Error breakdown:\")\n",
    "            for error_type, count in self.stats['errors'].items():\n",
    "                print(f\"  ‚Ä¢ {error_type}: {count}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "print(\"‚úÖ Robust OCR pipeline implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading dataset...\n",
      "Using Colab cache for faster access to the 'handwritten2text-training-dataset' dataset.\n",
      "‚úÖ Dataset: /kaggle/input/handwritten2text-training-dataset\n",
      "üìä Found 12111 images\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "print(\"üì• Downloading dataset...\")\n",
    "path = kagglehub.dataset_download(\"chaimaourgani/handwritten2text-training-dataset\")\n",
    "print(f\"‚úÖ Dataset: {path}\")\n",
    "\n",
    "# Find images\n",
    "dataset_path = Path(path)\n",
    "image_files = list(dataset_path.rglob('*.png')) + list(dataset_path.rglob('*.jpg'))\n",
    "print(f\"üìä Found {len(image_files)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Robust OCR Pipeline...\n",
      "üì¶ Loading TrOCR: microsoft/trocr-base-handwritten\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded on cpu\n",
      "\n",
      "‚úÖ Pipeline ready!\n"
     ]
    }
   ],
   "source": [
    "# Initialize robust pipeline\n",
    "pipeline = RobustOCRPipeline()\n",
    "print(\"\\n‚úÖ Pipeline ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process Documents with Error Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Processing 20 documents...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081fd73f17d7492e98badaab8a354535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä PROCESSING STATISTICS\n",
      "============================================================\n",
      "Total processed: 20\n",
      "‚úÖ Successful: 20 (100.0%)\n",
      "‚ùå Failed: 0 (0.0%)\n",
      "============================================================\n",
      "\n",
      "‚úÖ Successfully processed: 20\n",
      "‚ùå Failed: 0\n"
     ]
    }
   ],
   "source": [
    "# Process documents\n",
    "sample_size = 20  # Process 20 documents\n",
    "results = []\n",
    "\n",
    "print(f\"üîÑ Processing {sample_size} documents...\\n\")\n",
    "\n",
    "for img_path in tqdm(image_files[:sample_size], desc=\"Processing\"):\n",
    "    result = pipeline.process_document(img_path)\n",
    "    results.append(result)\n",
    "\n",
    "# Print statistics\n",
    "pipeline.print_stats()\n",
    "\n",
    "# Separate successful and failed\n",
    "successful_results = [r for r in results if r.success]\n",
    "failed_results = [r for r in results if not r.success]\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully processed: {len(successful_results)}\")\n",
    "print(f\"‚ùå Failed: {len(failed_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ SUCCESSFUL RESULTS\n",
      "================================================================================\n",
      "\n",
      "1. train2011-589_000005.jpg\n",
      "   Text: cordialement\n",
      "   Confidence: 72.17%\n",
      "   Fields: 0\n",
      "\n",
      "2. train2011-771_000002.jpg\n",
      "   Text: var le montant de mes impits eta puleri mensuellement .\n",
      "   Confidence: 67.54%\n",
      "   Fields: 0\n",
      "\n",
      "3. train2011-783_000005.jpg\n",
      "   Text: chossi de me brunnen vero vous . Twinensis can be presente was\n",
      "   Confidence: 52.30%\n",
      "   Fields: 0\n",
      "\n",
      "4. train2011-73_000003.jpg\n",
      "   Text: en ample sea commande over man couple client FNJBO14\n",
      "   Confidence: 61.20%\n",
      "   Fields: 0\n",
      "\n",
      "5. train2011-136_000001.jpg\n",
      "   Text: Te sonhaiterai commander their pains de chaussettes , taille 39142 ,\n",
      "   Confidence: 70.22%\n",
      "   Fields: 0\n"
     ]
    }
   ],
   "source": [
    "# Display successful results\n",
    "if successful_results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ SUCCESSFUL RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, result in enumerate(successful_results[:5], 1):\n",
    "        print(f\"\\n{i}. {Path(result.image_path).name}\")\n",
    "        print(f\"   Text: {result.raw_text[:100]}...\" if len(result.raw_text) > 100 else f\"   Text: {result.raw_text}\")\n",
    "        print(f\"   Confidence: {result.confidence:.2%}\")\n",
    "        print(f\"   Fields: {len(result.extracted_fields)}\")\n",
    "        if result.extracted_fields:\n",
    "            for key, value in list(result.extracted_fields.items())[:3]:\n",
    "                print(f\"     ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "# Display failed results with error details\n",
    "if failed_results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ùå FAILED RESULTS - Error Analysis\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, result in enumerate(failed_results[:10], 1):\n",
    "        print(f\"\\n{i}. {Path(result.image_path).name}\")\n",
    "        print(f\"   Error Type: {result.error_type}\")\n",
    "        print(f\"   Error Message: {result.error_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"85e0456a-2c47-4e0a-a8c2-ced528c52d1c\" class=\"plotly-graph-div\" style=\"height:400px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"85e0456a-2c47-4e0a-a8c2-ced528c52d1c\")) {                    Plotly.newPlot(                        \"85e0456a-2c47-4e0a-a8c2-ced528c52d1c\",                        [{\"marker\":{\"color\":\"lightblue\"},\"nbinsx\":20,\"x\":[0.7217071652412415,0.6754274964332581,0.5229954123497009,0.6119518280029297,0.7022073268890381,0.6489108204841614,0.7925960421562195,0.6189332008361816,0.752059817314148,0.7925662398338318,0.8718723654747009,0.4146997332572937,0.865306556224823,0.6241390109062195,0.5376983880996704,0.5928510427474976,0.5810753107070923,0.5986602902412415,0.7111921310424805,0.7017030715942383],\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Confidence Score Distribution (Successful Results)\"},\"xaxis\":{\"title\":{\"text\":\"Confidence\"}},\"yaxis\":{\"title\":{\"text\":\"Count\"}},\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('85e0456a-2c47-4e0a-a8c2-ced528c52d1c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä CONFIDENCE STATISTICS:\n",
      "   Mean: 66.69%\n",
      "   Std:  11.26%\n",
      "   Min:  41.47%\n",
      "   Max:  87.19%\n"
     ]
    }
   ],
   "source": [
    "if successful_results:\n",
    "    # Confidence distribution\n",
    "    confidences = [r.confidence for r in successful_results]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=confidences,\n",
    "        nbinsx=20,\n",
    "        marker_color='lightblue'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Confidence Score Distribution (Successful Results)',\n",
    "        xaxis_title='Confidence',\n",
    "        yaxis_title='Count',\n",
    "        height=400\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"\\nüìä CONFIDENCE STATISTICS:\")\n",
    "    print(f\"   Mean: {np.mean(confidences):.2%}\")\n",
    "    print(f\"   Std:  {np.std(confidences):.2%}\")\n",
    "    print(f\"   Min:  {np.min(confidences):.2%}\")\n",
    "    print(f\"   Max:  {np.max(confidences):.2%}\")\n",
    "\n",
    "# Error type distribution\n",
    "if failed_results:\n",
    "    error_types = Counter([r.error_type for r in failed_results])\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(error_types.keys()),\n",
    "        y=list(error_types.values()),\n",
    "        marker_color='lightcoral'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Error Type Distribution',\n",
    "        xaxis_title='Error Type',\n",
    "        yaxis_title='Count',\n",
    "        height=400\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported to: robust_ocr_results.json\n",
      "‚úÖ Exported summary to: processing_summary.csv\n",
      "\n",
      "üìÑ Summary Preview:\n",
      "                       image  success  \\\n",
      "0   train2011-589_000005.jpg     True   \n",
      "1   train2011-771_000002.jpg     True   \n",
      "2   train2011-783_000005.jpg     True   \n",
      "3    train2011-73_000003.jpg     True   \n",
      "4   train2011-136_000001.jpg     True   \n",
      "5   train2011-696_000004.jpg     True   \n",
      "6   train2011-227_000001.jpg     True   \n",
      "7   train2011-468_000007.jpg     True   \n",
      "8   train2011-985_000001.jpg     True   \n",
      "9  train2011-1274_000002.jpg     True   \n",
      "\n",
      "                                        text_preview  confidence  \\\n",
      "0                                       cordialement    0.721707   \n",
      "1  var le montant de mes impits eta puleri mensue...    0.675427   \n",
      "2  chossi de me brunnen vero vous . Twinensis can...    0.522995   \n",
      "3  en ample sea commande over man couple client F...    0.611952   \n",
      "4  Te sonhaiterai commander their pains de chauss...    0.702207   \n",
      "5  at que mei mame je travalle a mi. temps . Avec...    0.648911   \n",
      "6  Non-compagnon et moi-mieme_avens l'intention d...    0.792596   \n",
      "7  Ponsez - waves que ' ill suit mieux de placer ...    0.618933   \n",
      "8  I'dai bien regu un colis pour ma commande en date    0.752060   \n",
      "9  part de ma nouvelle streets . A ce jour je n'a...    0.792566   \n",
      "\n",
      "   fields_count error_type error_message  \n",
      "0             0                           \n",
      "1             0                           \n",
      "2             0                           \n",
      "3             0                           \n",
      "4             0                           \n",
      "5             0                           \n",
      "6             0                           \n",
      "7             0                           \n",
      "8             0                           \n",
      "9             0                           \n"
     ]
    }
   ],
   "source": [
    "# Export all results\n",
    "export_data = {\n",
    "    'summary': {\n",
    "        'total': len(results),\n",
    "        'successful': len(successful_results),\n",
    "        'failed': len(failed_results),\n",
    "        'success_rate': len(successful_results) / len(results) * 100 if results else 0\n",
    "    },\n",
    "    'successful_results': [r.to_dict() for r in successful_results],\n",
    "    'failed_results': [r.to_dict() for r in failed_results]\n",
    "}\n",
    "\n",
    "with open('robust_ocr_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úÖ Exported to: robust_ocr_results.json\")\n",
    "\n",
    "# Export CSV summary\n",
    "summary_data = []\n",
    "for result in results:\n",
    "    summary_data.append({\n",
    "        'image': Path(result.image_path).name,\n",
    "        'success': result.success,\n",
    "        'text_preview': result.raw_text[:50] if result.raw_text else '',\n",
    "        'confidence': result.confidence if result.confidence else 0,\n",
    "        'fields_count': len(result.extracted_fields) if result.extracted_fields else 0,\n",
    "        'error_type': result.error_type if not result.success else '',\n",
    "        'error_message': result.error_message[:50] if result.error_message else ''\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "df.to_csv('processing_summary.csv', index=False)\n",
    "print(\"‚úÖ Exported summary to: processing_summary.csv\")\n",
    "\n",
    "print(\"\\nüìÑ Summary Preview:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìã FINAL PROCESSING REPORT\n",
      "================================================================================\n",
      "\n",
      "üìä OVERVIEW:\n",
      "   ‚Ä¢ Total Documents: 20\n",
      "   ‚Ä¢ ‚úÖ Successful: 20 (100.0%)\n",
      "   ‚Ä¢ ‚ùå Failed: 0 (0.0%)\n",
      "\n",
      "‚úÖ SUCCESSFUL PROCESSING:\n",
      "   ‚Ä¢ Average Confidence: 66.69%\n",
      "   ‚Ä¢ Min Confidence: 41.47%\n",
      "   ‚Ä¢ Max Confidence: 87.19%\n",
      "   ‚Ä¢ Total Fields Extracted: 0\n",
      "   ‚Ä¢ Avg Fields per Doc: 0.0\n",
      "\n",
      "üíæ EXPORTS:\n",
      "   ‚Ä¢ Detailed JSON: robust_ocr_results.json\n",
      "   ‚Ä¢ Summary CSV: processing_summary.csv\n",
      "\n",
      "‚úÖ Processing Complete!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã FINAL PROCESSING REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "success_rate = len(successful_results) / len(results) * 100 if results else 0\n",
    "\n",
    "report = f\"\"\"\n",
    "üìä OVERVIEW:\n",
    "   ‚Ä¢ Total Documents: {len(results)}\n",
    "   ‚Ä¢ ‚úÖ Successful: {len(successful_results)} ({success_rate:.1f}%)\n",
    "   ‚Ä¢ ‚ùå Failed: {len(failed_results)} ({100-success_rate:.1f}%)\n",
    "\"\"\"\n",
    "\n",
    "if successful_results:\n",
    "    confidences = [r.confidence for r in successful_results]\n",
    "    total_fields = sum(len(r.extracted_fields) for r in successful_results if r.extracted_fields)\n",
    "    \n",
    "    report += f\"\"\"\n",
    "‚úÖ SUCCESSFUL PROCESSING:\n",
    "   ‚Ä¢ Average Confidence: {np.mean(confidences):.2%}\n",
    "   ‚Ä¢ Min Confidence: {np.min(confidences):.2%}\n",
    "   ‚Ä¢ Max Confidence: {np.max(confidences):.2%}\n",
    "   ‚Ä¢ Total Fields Extracted: {total_fields}\n",
    "   ‚Ä¢ Avg Fields per Doc: {total_fields/len(successful_results):.1f}\n",
    "\"\"\"\n",
    "\n",
    "if failed_results:\n",
    "    error_types = Counter([r.error_type for r in failed_results])\n",
    "    \n",
    "    report += f\"\"\"\n",
    "‚ùå FAILURE ANALYSIS:\n",
    "\"\"\"\n",
    "    for error_type, count in error_types.most_common():\n",
    "        report += f\"   ‚Ä¢ {error_type}: {count} ({count/len(failed_results)*100:.1f}%)\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "üíæ EXPORTS:\n",
    "   ‚Ä¢ Detailed JSON: robust_ocr_results.json\n",
    "   ‚Ä¢ Summary CSV: processing_summary.csv\n",
    "\n",
    "‚úÖ Processing Complete!\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Fixes Implemented:\n",
    "\n",
    "### 1. Type Checking & Validation\n",
    "- ‚úÖ Validates image dtype before processing\n",
    "- ‚úÖ Converts `np.object_` arrays safely\n",
    "- ‚úÖ Handles float/int type conversions\n",
    "- ‚úÖ Validates image dimensions\n",
    "\n",
    "### 2. Error Handling\n",
    "- ‚úÖ Try-except blocks at every level\n",
    "- ‚úÖ Detailed error messages\n",
    "- ‚úÖ Error categorization (preprocessing, recognition, unknown)\n",
    "- ‚úÖ Graceful failure handling\n",
    "\n",
    "### 3. Fallback Mechanisms\n",
    "- ‚úÖ OpenCV ‚Üí PIL fallback for image loading\n",
    "- ‚úÖ Sauvola ‚Üí Otsu fallback for thresholding\n",
    "- ‚úÖ Default confidence scores when calculation fails\n",
    "\n",
    "### 4. Statistics & Monitoring\n",
    "- ‚úÖ Track success/failure rates\n",
    "- ‚úÖ Error type breakdown\n",
    "- ‚úÖ Processing statistics\n",
    "- ‚úÖ Detailed failure analysis\n",
    "\n",
    "### 5. Output\n",
    "- ‚úÖ Separate successful and failed results\n",
    "- ‚úÖ Detailed error messages for debugging\n",
    "- ‚úÖ Comprehensive reporting\n",
    "- ‚úÖ CSV export with error details\n",
    "\n",
    "---\n",
    "\n",
    "**This version will handle problematic images gracefully and provide detailed error information for debugging!**\n",
    "\n",
    "**SOCAR Hackathon 2025** | **AI Engineering Track**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
